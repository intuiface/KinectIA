# Kinect Interface Assets for IntuiFace

This project contains Microsoft Kinect Interface Assets for IntuiFace Player & IntuiFace Composer.

The [Microsoft Kinect](http://www.microsoft.com/en-us/kinectforwindows/) Interface Assets enable you to control an IntuiFace experience using the Microsoft Kinect sensor. 
IntuiFace provides a set of gestures and postures as well as presence detection to trigger any action in your experience. You can also manipulate assets directly using hand pointing.

There are six available Kinect Interface Assets, accessible in the Select an interface panel:

* [Kinect Settings](http://support.intuilab.com/kb/non-touch-interactive-devices/using-microsoftr-kinectr#kinectSettings): used to change Kinect sensor settings
* [People Detection](http://support.intuilab.com/kb/non-touch-interactive-devices/using-microsoftr-kinectr#peopleDetection): detects people in front of the Kinect sensor and displays a live video of sensor input
* [Gestures](http://support.intuilab.com/kb/non-touch-interactive-devices/using-microsoftr-kinectr#gestures): manages gestures detection
* [Letter Postures](http://support.intuilab.com/kb/non-touch-interactive-devices/using-microsoftr-kinectr#letterPostures): manages letter postures detection
* [Command Postures](http://support.intuilab.com/kb/non-touch-interactive-devices/using-microsoftr-kinectr#commandPostures): manages command postures detection
* [Hand Pointing](http://support.intuilab.com/kb/non-touch-interactive-devices/using-microsoftr-kinectr#handPointing): enables direct object manipulation as if you were touching the display with your hands

See more information on our support webpage: [Using Microsoft Kinect in IntuiFace Composer](http://support.intuilab.com/kb/non-touch-interactive-devices/using-microsoftr-kinectr).

# How to compile this project?

The code for this Interface Asset is C#.

# How to use Kinect Interface Asset?



